{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to change\n",
    "# Features\n",
    "# PCA of pixel vector\n",
    "# Split of training, test data\n",
    "# C value of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# sklearn libraries for preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn libraries for models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn libraries for evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('C:/Users/user/Documents/Berkeley_MIDS/W207_Machine_Learning/w207_final_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0', 'arr_1']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load first npz file as an example and get files\n",
    "data_1 = np.load('et_w207_project_npz_files_5000_tmp_tmp5ocrhjnn.npz')\n",
    "data_1.close\n",
    "data_1.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ozbpir-9ey6js-ggdqwo', '378ykanq', 'p366md-big834-7o23k6',\n",
       "       '3zruwvl2', 'q18iae-3vnh74-79npmy'], dtype='<U20')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show file arr_0 example\n",
    "data_1['arr_0'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-103.939   , -116.779   , -123.68    , ..., -103.939   ,\n",
       "        -116.779   , -123.68    ],\n",
       "       [ -46.939003,  -74.779   , -118.68    , ...,  -57.939003,\n",
       "         -84.779   , -118.68    ],\n",
       "       [ 151.061   ,  138.22101 ,  131.32    , ...,  151.061   ,\n",
       "         138.22101 ,  131.32    ],\n",
       "       [  -3.939003,  -66.779   ,  -96.68    , ...,   -3.939003,\n",
       "         -66.779   ,  -96.68    ],\n",
       "       [-103.939   , -116.779   , -123.68    , ..., -103.939   ,\n",
       "        -116.779   , -123.68    ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show file arr_1 example\n",
    "data_1['arr_1'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "['arr_0', 'arr_1']\n",
      "['arr_0', 'arr_1']\n"
     ]
    }
   ],
   "source": [
    "# Load all data files\n",
    "data_2 = np.load('et_w207_project_npz_files_5000_tmp_tmp092sag67.npz')\n",
    "data_2.close\n",
    "print(data_2.files)\n",
    "\n",
    "data_3 = np.load('et_w207_project_npz_files_5000_tmp_tmpf31_pn8p.npz')\n",
    "data_3.close\n",
    "print(data_3.files)\n",
    "\n",
    "data_4 = np.load('et_w207_project_npz_files_5000_tmp_tmpq5b2g4n2.npz')\n",
    "data_4.close\n",
    "print(data_4.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878,)\n",
      "(878, 150528)\n"
     ]
    }
   ],
   "source": [
    "# Get size of each file\n",
    "print(data_1['arr_0'].shape)\n",
    "print(data_1['arr_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(893,)\n",
      "(893, 150528)\n"
     ]
    }
   ],
   "source": [
    "print(data_2['arr_0'].shape)\n",
    "print(data_2['arr_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(638,)\n",
      "(638, 150528)\n"
     ]
    }
   ],
   "source": [
    "print(data_3['arr_0'].shape)\n",
    "print(data_3['arr_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353,)\n",
      "(1353, 150528)\n"
     ]
    }
   ],
   "source": [
    "print(data_4['arr_0'].shape)\n",
    "print(data_4['arr_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate image vectors from all files\n",
    "# Concatenate data from all files\n",
    "data_key = np.concatenate((data_1['arr_0'], data_2['arr_0'], data_3['arr_0'], data_4['arr_0']))\n",
    "print(data_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 150528)\n"
     ]
    }
   ],
   "source": [
    "data_pixel = np.concatenate((data_1['arr_1'], data_2['arr_1'], data_3['arr_1'], data_4['arr_1']))\n",
    "print(data_pixel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_array</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attachment_key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ozbpir-9ey6js-ggdqwo</td>\n",
       "      <td>[-0.40760392, -0.45795685, -0.4850196, -0.4076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378ykanq</td>\n",
       "      <td>[-0.18407452, -0.29325098, -0.46541175, -0.097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>p366md-big834-7o23k6</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3zruwvl2</td>\n",
       "      <td>[-0.015447071, -0.26187843, -0.37913725, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>q18iae-3vnh74-79npmy</td>\n",
       "      <td>[-0.40760392, -0.45795685, -0.4850196, -0.4076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pktyig-481wyg-6gyulf</td>\n",
       "      <td>[-0.3605451, -0.41089803, -0.38305882, -0.3644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>zu7y3rha</td>\n",
       "      <td>[-0.007603933, -0.05795686, -0.08501961, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pxcwxf-8tnpyg-8vhb9r</td>\n",
       "      <td>[0.3022, 0.18125883, 0.12674509, 0.31004313, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>p4hakf-fsskmw-1224up</td>\n",
       "      <td>[-0.40368235, -0.45403528, -0.48109803, -0.387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ptuhsk-22124o-f0sxoc</td>\n",
       "      <td>[0.43945488, 0.39302352, 0.3502745, 0.44729802...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3759 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            pixel_array\n",
       "attachment_key                                                         \n",
       "ozbpir-9ey6js-ggdqwo  [-0.40760392, -0.45795685, -0.4850196, -0.4076...\n",
       "378ykanq              [-0.18407452, -0.29325098, -0.46541175, -0.097...\n",
       "p366md-big834-7o23k6  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...\n",
       "3zruwvl2              [-0.015447071, -0.26187843, -0.37913725, -0.01...\n",
       "q18iae-3vnh74-79npmy  [-0.40760392, -0.45795685, -0.4850196, -0.4076...\n",
       "...                                                                 ...\n",
       "pktyig-481wyg-6gyulf  [-0.3605451, -0.41089803, -0.38305882, -0.3644...\n",
       "zu7y3rha              [-0.007603933, -0.05795686, -0.08501961, -0.00...\n",
       "pxcwxf-8tnpyg-8vhb9r  [0.3022, 0.18125883, 0.12674509, 0.31004313, 0...\n",
       "p4hakf-fsskmw-1224up  [-0.40368235, -0.45403528, -0.48109803, -0.387...\n",
       "ptuhsk-22124o-f0sxoc  [0.43945488, 0.39302352, 0.3502745, 0.44729802...\n",
       "\n",
       "[3759 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store pixel vectors as DF with attachment key\n",
    "\n",
    "# Create key value pairs with arr0 (attachment key) and standardized arr1 (pixel array)\n",
    "# Standardize pixel values between 0 and 1 by dividing by 255\n",
    "data_dict = {}\n",
    "for i in range(data_key.shape[0]):\n",
    "    data_dict[data_key[i]] = [data_pixel[i]/255]\n",
    "\n",
    "df_pixel = pd.DataFrame(data=data_dict)\n",
    "df_pixel_t = df_pixel.transpose()\n",
    "df_pixel_t.index.names = ['attachment_key']\n",
    "df_pixel_t.columns = ['pixel_array']\n",
    "df_pixel_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_key</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>h_to_w</th>\n",
       "      <th>filename</th>\n",
       "      <th>logo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>001lq61k</td>\n",
       "      <td>0.122520</td>\n",
       "      <td>514.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.713889</td>\n",
       "      <td>campus ministry on the beach.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>002dlirq</td>\n",
       "      <td>3.256944</td>\n",
       "      <td>4072.0</td>\n",
       "      <td>3868.0</td>\n",
       "      <td>1.052741</td>\n",
       "      <td>BIG ALS FISH FLASH UV VP PL.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>003qefgm</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>80.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>netix_email_studio.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0083okjl</td>\n",
       "      <td>0.116802</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>productshot2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00a957mh</td>\n",
       "      <td>0.140714</td>\n",
       "      <td>816.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>0.342569</td>\n",
       "      <td>divine_medical_billing_inc_master.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attachment_key   size_mb  height   width    h_to_w  \\\n",
       "0       001lq61k  0.122520   514.0   720.0  0.713889   \n",
       "1       002dlirq  3.256944  4072.0  3868.0  1.052741   \n",
       "2       003qefgm  0.002522    80.0   200.0  0.400000   \n",
       "3       0083okjl  0.116802   600.0   600.0  1.000000   \n",
       "4       00a957mh  0.140714   816.0  2382.0  0.342569   \n",
       "\n",
       "                                filename  logo  \n",
       "0       campus ministry on the beach.jpg     0  \n",
       "1        BIG ALS FISH FLASH UV VP PL.jpg     0  \n",
       "2                 netix_email_studio.png     1  \n",
       "3                       productshot2.jpg     0  \n",
       "4  divine_medical_billing_inc_master.png     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load excel data\n",
    "df = pd.read_csv('school_project_data_set-new.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_key</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>h_to_w</th>\n",
       "      <th>filename</th>\n",
       "      <th>logo</th>\n",
       "      <th>pixel_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00xjny6u</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>520.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1.027668</td>\n",
       "      <td>Esterdale Theatre - Logo.png</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>04o31jop</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>269.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.679293</td>\n",
       "      <td>BLUE_LOGO.png</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0840h7ox</td>\n",
       "      <td>0.399114</td>\n",
       "      <td>518.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>ZEN_LB-5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.106121555, 0.05576863, 0.052235294, 0.09043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0awudx2h</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>article central 200.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0bb8y85h</td>\n",
       "      <td>0.263813</td>\n",
       "      <td>885.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>1116-100_WGTank_white.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>zu7y3rha</td>\n",
       "      <td>0.147371</td>\n",
       "      <td>498.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>journalism.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.007603933, -0.05795686, -0.08501961, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3751</td>\n",
       "      <td>zuanbsqe</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>206.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>0.496386</td>\n",
       "      <td>2013 05 26_techstars_id_final_bug solo graysca...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3752</td>\n",
       "      <td>zw9234v4</td>\n",
       "      <td>2.021135</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1.134483</td>\n",
       "      <td>SPIN N GLO SILVER WING GPK MY.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3753</td>\n",
       "      <td>zxfqbfj1</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>36.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>cornerstone web logo medium.png</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.40760392, -0.45795685, -0.4850196, -0.4076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3754</td>\n",
       "      <td>zzgkjqna</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>56.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>fieldcontrolslogohorz web.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3755 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     attachment_key   size_mb  height   width    h_to_w  \\\n",
       "0          00xjny6u  0.011849   520.0   506.0  1.027668   \n",
       "1          04o31jop  0.012610   269.0   396.0  0.679293   \n",
       "2          0840h7ox  0.399114   518.0   920.0  0.563044   \n",
       "3          0awudx2h  0.011226   200.0   200.0  1.000000   \n",
       "4          0bb8y85h  0.263813   885.0   800.0  1.106250   \n",
       "...             ...       ...     ...     ...       ...   \n",
       "3750       zu7y3rha  0.147371   498.0   702.0  0.709402   \n",
       "3751       zuanbsqe  0.580392   206.0   415.0  0.496386   \n",
       "3752       zw9234v4  2.021135  1645.0  1450.0  1.134483   \n",
       "3753       zxfqbfj1  0.012057    36.0   345.0  0.104348   \n",
       "3754       zzgkjqna  0.027983    56.0   350.0  0.160000   \n",
       "\n",
       "                                               filename  logo  \\\n",
       "0                          Esterdale Theatre - Logo.png     1   \n",
       "1                                         BLUE_LOGO.png     1   \n",
       "2                                          ZEN_LB-5.jpg     0   \n",
       "3                               article central 200.jpg     1   \n",
       "4                             1116-100_WGTank_white.jpg     0   \n",
       "...                                                 ...   ...   \n",
       "3750                                     journalism.jpg     0   \n",
       "3751  2013 05 26_techstars_id_final_bug solo graysca...     1   \n",
       "3752                  SPIN N GLO SILVER WING GPK MY.jpg     0   \n",
       "3753                    cornerstone web logo medium.png     1   \n",
       "3754                      fieldcontrolslogohorz web.jpg     1   \n",
       "\n",
       "                                            pixel_array  \n",
       "0     [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "1     [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "2     [0.106121555, 0.05576863, 0.052235294, 0.09043...  \n",
       "3     [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "4     [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "...                                                 ...  \n",
       "3750  [-0.007603933, -0.05795686, -0.08501961, -0.00...  \n",
       "3751  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "3752  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "3753  [-0.40760392, -0.45795685, -0.4850196, -0.4076...  \n",
       "3754  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  \n",
       "\n",
       "[3755 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dataframes by attachment key\n",
    "merge_meta_pixel = df.merge(df_pixel_t, on='attachment_key')\n",
    "merge_meta_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3754 entries, 0 to 3754\n",
      "Data columns (total 8 columns):\n",
      "attachment_key    3754 non-null object\n",
      "size_mb           3754 non-null float64\n",
      "height            3754 non-null float64\n",
      "width             3754 non-null float64\n",
      "h_to_w            3754 non-null float64\n",
      "filename          3754 non-null object\n",
      "logo              3754 non-null int64\n",
      "pixel_array       3754 non-null object\n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 264.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null values\n",
    "merge_meta_pixel = merge_meta_pixel[merge_meta_pixel.height.notnull()]\n",
    "merge_meta_pixel.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'peg', 'pig', 'png', 'jpe', 'lue', 'hot', 'jpg', 'ack', 'age', '73e', '0mm', 'ite'}\n"
     ]
    }
   ],
   "source": [
    "# Find file types from filename\n",
    "file_types = []\n",
    "for item in merge_meta_pixel['filename']:\n",
    "    file_types.append(item[-3:].lower())\n",
    "\n",
    "print(set(file_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of file types from filename to append to df\n",
    "filetype_encoding = []\n",
    "for item in merge_meta_pixel['filename']:\n",
    "    if item[-3:].lower() == 'jpg':\n",
    "        filetype_encoding.append('jpg')\n",
    "    elif item[-3:].lower() == 'png':\n",
    "        filetype_encoding.append('png')\n",
    "    else:\n",
    "        filetype_encoding.append('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_key</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>h_to_w</th>\n",
       "      <th>filetype</th>\n",
       "      <th>pixel_array</th>\n",
       "      <th>filename</th>\n",
       "      <th>logo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00xjny6u</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>520.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1.027668</td>\n",
       "      <td>png</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>Esterdale Theatre - Logo.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>04o31jop</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>269.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.679293</td>\n",
       "      <td>png</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>BLUE_LOGO.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0840h7ox</td>\n",
       "      <td>0.399114</td>\n",
       "      <td>518.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>jpg</td>\n",
       "      <td>[0.106121555, 0.05576863, 0.052235294, 0.09043...</td>\n",
       "      <td>ZEN_LB-5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0awudx2h</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>jpg</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>article central 200.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0bb8y85h</td>\n",
       "      <td>0.263813</td>\n",
       "      <td>885.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>jpg</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>1116-100_WGTank_white.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attachment_key   size_mb  height  width    h_to_w filetype  \\\n",
       "0       00xjny6u  0.011849   520.0  506.0  1.027668      png   \n",
       "1       04o31jop  0.012610   269.0  396.0  0.679293      png   \n",
       "2       0840h7ox  0.399114   518.0  920.0  0.563044      jpg   \n",
       "3       0awudx2h  0.011226   200.0  200.0  1.000000      jpg   \n",
       "4       0bb8y85h  0.263813   885.0  800.0  1.106250      jpg   \n",
       "\n",
       "                                         pixel_array  \\\n",
       "0  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "1  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "2  [0.106121555, 0.05576863, 0.052235294, 0.09043...   \n",
       "3  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "4  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "\n",
       "                       filename  logo  \n",
       "0  Esterdale Theatre - Logo.png     1  \n",
       "1                 BLUE_LOGO.png     1  \n",
       "2                  ZEN_LB-5.jpg     0  \n",
       "3       article central 200.jpg     1  \n",
       "4     1116-100_WGTank_white.jpg     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df that includes column for file type\n",
    "merge_meta_pixel['filetype'] = filetype_encoding\n",
    "merge_meta_pixel = merge_meta_pixel[['attachment_key', 'size_mb', 'height', 'width', 'h_to_w', 'filetype', 'pixel_array', 'filename','logo']]\n",
    "merge_meta_pixel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_key</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>h_to_w</th>\n",
       "      <th>filetype</th>\n",
       "      <th>pixel_array</th>\n",
       "      <th>filename</th>\n",
       "      <th>logo</th>\n",
       "      <th>jpg</th>\n",
       "      <th>other</th>\n",
       "      <th>png</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00xjny6u</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>520.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1.027668</td>\n",
       "      <td>png</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>Esterdale Theatre - Logo.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>04o31jop</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>269.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.679293</td>\n",
       "      <td>png</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>BLUE_LOGO.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0840h7ox</td>\n",
       "      <td>0.399114</td>\n",
       "      <td>518.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>jpg</td>\n",
       "      <td>[0.106121555, 0.05576863, 0.052235294, 0.09043...</td>\n",
       "      <td>ZEN_LB-5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0awudx2h</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>jpg</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>article central 200.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0bb8y85h</td>\n",
       "      <td>0.263813</td>\n",
       "      <td>885.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>jpg</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>1116-100_WGTank_white.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attachment_key   size_mb  height  width    h_to_w filetype  \\\n",
       "0       00xjny6u  0.011849   520.0  506.0  1.027668      png   \n",
       "1       04o31jop  0.012610   269.0  396.0  0.679293      png   \n",
       "2       0840h7ox  0.399114   518.0  920.0  0.563044      jpg   \n",
       "3       0awudx2h  0.011226   200.0  200.0  1.000000      jpg   \n",
       "4       0bb8y85h  0.263813   885.0  800.0  1.106250      jpg   \n",
       "\n",
       "                                         pixel_array  \\\n",
       "0  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "1  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "2  [0.106121555, 0.05576863, 0.052235294, 0.09043...   \n",
       "3  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "4  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...   \n",
       "\n",
       "                       filename  logo  jpg  other  png  \n",
       "0  Esterdale Theatre - Logo.png     1    0      0    1  \n",
       "1                 BLUE_LOGO.png     1    0      0    1  \n",
       "2                  ZEN_LB-5.jpg     0    1      0    0  \n",
       "3       article central 200.jpg     1    1      0    0  \n",
       "4     1116-100_WGTank_white.jpg     0    1      0    0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummies for file type\n",
    "filetype_dummies = pd.get_dummies(merge_meta_pixel.filetype)\n",
    "\n",
    "# add to initial df\n",
    "merge_meta_pixel = pd.concat((merge_meta_pixel, filetype_dummies), axis=1)\n",
    "\n",
    "# print head of df\n",
    "merge_meta_pixel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_key</th>\n",
       "      <th>pixel_array</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>h_to_w</th>\n",
       "      <th>jpg</th>\n",
       "      <th>png</th>\n",
       "      <th>other</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>logo</th>\n",
       "      <th>filetype</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00xjny6u</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>1.027668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1</td>\n",
       "      <td>png</td>\n",
       "      <td>Esterdale Theatre - Logo.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>04o31jop</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.679293</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1</td>\n",
       "      <td>png</td>\n",
       "      <td>BLUE_LOGO.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0840h7ox</td>\n",
       "      <td>[0.106121555, 0.05576863, 0.052235294, 0.09043...</td>\n",
       "      <td>0.399114</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>jpg</td>\n",
       "      <td>ZEN_LB-5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0awudx2h</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>jpg</td>\n",
       "      <td>article central 200.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0bb8y85h</td>\n",
       "      <td>[0.5923961, 0.54204315, 0.51498044, 0.5923961,...</td>\n",
       "      <td>0.263813</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1116-100_WGTank_white.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attachment_key                                        pixel_array   size_mb  \\\n",
       "0       00xjny6u  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  0.011849   \n",
       "1       04o31jop  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  0.012610   \n",
       "2       0840h7ox  [0.106121555, 0.05576863, 0.052235294, 0.09043...  0.399114   \n",
       "3       0awudx2h  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  0.011226   \n",
       "4       0bb8y85h  [0.5923961, 0.54204315, 0.51498044, 0.5923961,...  0.263813   \n",
       "\n",
       "     h_to_w  jpg  png  other  height  width  logo filetype  \\\n",
       "0  1.027668    0    1      0   520.0  506.0     1      png   \n",
       "1  0.679293    0    1      0   269.0  396.0     1      png   \n",
       "2  0.563044    1    0      0   518.0  920.0     0      jpg   \n",
       "3  1.000000    1    0      0   200.0  200.0     1      jpg   \n",
       "4  1.106250    1    0      0   885.0  800.0     0      jpg   \n",
       "\n",
       "                       filename  \n",
       "0  Esterdale Theatre - Logo.png  \n",
       "1                 BLUE_LOGO.png  \n",
       "2                  ZEN_LB-5.jpg  \n",
       "3       article central 200.jpg  \n",
       "4     1116-100_WGTank_white.jpg  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize df to separate into feature arrays\n",
    "merge_meta_pixel = merge_meta_pixel[['attachment_key', 'pixel_array', 'size_mb', 'h_to_w', 'jpg', 'png', 'other',\n",
    "                                     'height', 'width', 'logo', 'filetype', 'filename']]\n",
    "merge_meta_pixel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale continuous feature variables\n",
    "merge_meta_pixel['size_mb'] = preprocessing.scale(merge_meta_pixel['size_mb'])\n",
    "merge_meta_pixel['h_to_w'] = preprocessing.scale(merge_meta_pixel['h_to_w'])\n",
    "merge_meta_pixel['height'] = preprocessing.scale(merge_meta_pixel['height'])\n",
    "merge_meta_pixel['width'] = preprocessing.scale(merge_meta_pixel['width'])\n",
    "\n",
    "# Standardize data\n",
    "#scaler = StandardScaler() \n",
    "#scaled_df = scaler.fit_transform(raw_df) \n",
    "  \n",
    "# Normalizing the Data \n",
    "#normalized_df = normalize(scaled_df) \n",
    "  \n",
    "# Converting the numpy array into a pandas DataFrame \n",
    "#normalized_df = pd.DataFrame(normalized_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3754, 150528)\n",
      "(3754, 9)\n",
      "(3754, 7)\n",
      "(3754, 4)\n",
      "(3754, 5)\n",
      "(3754, 7)\n",
      "(3754, 5)\n"
     ]
    }
   ],
   "source": [
    "# y array contains logo/not logo binary variable\n",
    "y = np.array(merge_meta_pixel.iloc[:, 9])\n",
    "\n",
    "# X array contains pixel array only\n",
    "X = np.array(merge_meta_pixel['pixel_array'].tolist())\n",
    "print(X.shape)\n",
    "\n",
    "# Reducing dimensions of the pixel data\n",
    "def reduce(X, n):\n",
    "    '''PCA dimensionality reduction for X array and n principal components'''\n",
    "    pca = PCA(n_components = n) \n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    return X_reduced\n",
    "\n",
    "X_reduced = reduce(X,2)\n",
    "\n",
    "# Create variations of X array with reduced pixel data and different metadata features\n",
    "\n",
    "# X2 array contains pixel features, size, height, width, h_to_w, filetype dummies\n",
    "X2 = np.concatenate((X_reduced, np.array(merge_meta_pixel.iloc[:, 2:9])),axis=1)\n",
    "print(X2.shape)\n",
    "\n",
    "# X3 array contains pixel features, size, h_to_w, filetype dummies\n",
    "X3 = np.concatenate((X_reduced, np.array(merge_meta_pixel.iloc[:, 2:7])),axis=1)\n",
    "print(X3.shape)\n",
    "\n",
    "# X4 array contains pixel array, size, h_to_w\n",
    "X4 = np.concatenate((X_reduced, np.array(merge_meta_pixel.iloc[:, 2:4])),axis=1)\n",
    "print(X4.shape)\n",
    "\n",
    "# X5 array contains pixel array, filetype dummies \n",
    "X5 = np.concatenate((X_reduced, np.array(merge_meta_pixel.iloc[:, 4:7])),axis=1)\n",
    "print(X5.shape)\n",
    "\n",
    "# X6 array contains size, height, width, h_to_w, filetype\n",
    "X6 = np.array(merge_meta_pixel.iloc[:, 2:9])\n",
    "print(X6.shape)\n",
    "\n",
    "# X7 array contains size, h_to_w, filetype\n",
    "X7 = np.array(merge_meta_pixel.iloc[:, 2:7])\n",
    "print(X7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, test_p, mini_s):\n",
    "    '''Split train and test data for X,y data arrays with test_p percentage of observations in the test data and \n",
    "    mini_s number of observations in the mini_train set'''\n",
    "    # Split into train and test data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=test_p, random_state=1, stratify=y)\n",
    "\n",
    "    # Split test data into development data and training into mini train set for computation time\n",
    "    dev_data, dev_labels = test_data[:int(test_data.shape[0]*0.5)], test_labels[:int(test_data.shape[0]*0.5)]\n",
    "    mini_train_data, mini_train_labels = train_data[:mini_s], train_labels[:mini_s]\n",
    "    print('Train data shape:', train_data.shape)\n",
    "    print('Dev data shape:', dev_data.shape)\n",
    "    print('Mini_train data shape:', mini_train_data.shape)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels, dev_data, dev_labels, mini_train_data, mini_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2252, 2)\n",
      "Dev data shape: (751, 2)\n",
      "Mini_train data shape: (100, 2)\n",
      "Train data shape: (2252, 9)\n",
      "Dev data shape: (751, 9)\n",
      "Mini_train data shape: (100, 9)\n",
      "Train data shape: (2252, 7)\n",
      "Dev data shape: (751, 7)\n",
      "Mini_train data shape: (100, 7)\n",
      "Train data shape: (2252, 4)\n",
      "Dev data shape: (751, 4)\n",
      "Mini_train data shape: (100, 4)\n",
      "Train data shape: (2252, 5)\n",
      "Dev data shape: (751, 5)\n",
      "Mini_train data shape: (100, 5)\n",
      "Train data shape: (2252, 7)\n",
      "Dev data shape: (751, 7)\n",
      "Mini_train data shape: (100, 7)\n",
      "Train data shape: (2252, 5)\n",
      "Dev data shape: (751, 5)\n",
      "Mini_train data shape: (100, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split all feature combinations into train, test data\n",
    "train_data, train_labels, test_data, test_labels, dev_data, dev_labels, mini_train_data, mini_train_labels = data_split(X_reduced, y, 0.4, 100)\n",
    "train_data2, train_labels2, test_data2, test_labels2, dev_data2, dev_labels2, mini_train_data2, mini_train_labels2 = data_split(X2, y, 0.4, 100)\n",
    "train_data3, train_labels3, test_data3, test_labels3, dev_data3, dev_labels3, mini_train_data3, mini_train_labels3 = data_split(X3, y, 0.4, 100)\n",
    "train_data4, train_labels4, test_data4, test_labels4, dev_data4, dev_labels4, mini_train_data4, mini_train_labels4 = data_split(X4, y, 0.4, 100)\n",
    "train_data5, train_labels5, test_data5, test_labels5, dev_data5, dev_labels5, mini_train_data5, mini_train_labels5 = data_split(X5, y, 0.4, 100)\n",
    "train_data6, train_labels6, test_data6, test_labels6, dev_data6, dev_labels6, mini_train_data6, mini_train_labels6 = data_split(X6, y, 0.4, 100)\n",
    "train_data7, train_labels7, test_data7, test_labels7, dev_data7, dev_labels7, mini_train_data7, mini_train_labels7 = data_split(X7, y, 0.4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize pixel values between 0 and 1 by dividing by 255\n",
    "#data = [train_data, test_data, dev_data, mini_train_data]\n",
    "\n",
    "#print(train_data)\n",
    "\n",
    "#for element in data:\n",
    "#    for array in element:\n",
    "#        for value in array:\n",
    "#            value = value/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(train_X, train_Y, dev_X, dev_Y):\n",
    "    '''Logistic regression looping through values of C'''\n",
    "    c_values = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0, 5.0]\n",
    "    LR = []\n",
    "    for c in c_values:\n",
    "        clf = LogisticRegression(C=c, solver='liblinear', multi_class='auto')\n",
    "        clf.fit(train_X, train_Y)\n",
    "        clf_pred = clf.predict(dev_X)\n",
    "        LR.append(round(metrics.f1_score(dev_Y, clf_pred, average='weighted'),3))\n",
    "\n",
    "    return LR, c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR REFERENCE\n",
    "# X array contains pixel array only\n",
    "# X2 array contains pixel array, size, h_to_w, filetype dummies\n",
    "# X3 array contains pixel array, size, h_to_w\n",
    "# X4 array contains pixel array, size\n",
    "# X5 array contains pixel array, h_to_w \n",
    "# X6 array contains pixel array, filetype dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_accuracy_c(train_X, train_Y, dev_X, dev_Y):\n",
    "    accuracy_list = log_reg(train_X, train_Y, dev_X, dev_Y)[0]\n",
    "    accuracy = [y for x,y in sorted(enumerate(accuracy_list), key = lambda x: x[1], reverse=True)][:1]\n",
    "    accuracy_index = [x for x,y in sorted(enumerate(accuracy_list), key = lambda x: x[1], reverse=True)][:1]\n",
    "    C = log_reg(train_X, train_Y, dev_X, dev_Y)[1][accuracy_index[0]]\n",
    "    \n",
    "    return accuracy[0], C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: pixel features only\n",
      "Best Accuracy: 0.577, c=0.001\n"
     ]
    }
   ],
   "source": [
    "# Pixel array only\n",
    "# Run LR and output best accuracy with c value\n",
    "print('Features: pixel features only\\nBest Accuracy: {}, c={}'.format(\n",
    "    LR_accuracy_c(train_data, train_labels, dev_data, dev_labels)[0],\n",
    "    LR_accuracy_c(train_data, train_labels, dev_data, dev_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: pixel features, size, height, width, h_to_w, filetype dummies\n",
      "Best Accuracy: 0.858, c=0.1\n",
      "\n",
      "Features: pixel features, size, h_to_w, filetype dummies\n",
      "Best Accuracy: 0.849, c=2.0\n",
      "\n",
      "Features: pixel features, size, h_to_w\n",
      "Best Accuracy: 0.768, c=0.3\n",
      "\n",
      "Features: pixel features, filetype dummies\n",
      "Best Accuracy: 0.822, c=0.2\n",
      "\n",
      "Features: size, height, width, h_to_w, filetype\n",
      "Best Accuracy: 0.845, c=0.1\n",
      "\n",
      "Features: size, h_to_w, filetype\n",
      "Best Accuracy: 0.849, c=0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LR and output best accuracies with c values for each combination of features\n",
    "print('Features: pixel features, size, height, width, h_to_w, filetype dummies\\nBest Accuracy: {}, c={}\\n'.format(\n",
    "    LR_accuracy_c(train_data2, train_labels2, dev_data2, dev_labels2)[0],\n",
    "    LR_accuracy_c(train_data2, train_labels2, dev_data2, dev_labels2)[1]))\n",
    "\n",
    "print('Features: pixel features, size, h_to_w, filetype dummies\\nBest Accuracy: {}, c={}\\n'.format(\n",
    "    LR_accuracy_c(train_data3, train_labels3, dev_data3, dev_labels3)[0],\n",
    "    LR_accuracy_c(train_data3, train_labels3, dev_data3, dev_labels3)[1]))\n",
    "\n",
    "print('Features: pixel features, size, h_to_w\\nBest Accuracy: {}, c={}\\n'.format(\n",
    "    LR_accuracy_c(train_data4, train_labels4, dev_data4, dev_labels4)[0],\n",
    "    LR_accuracy_c(train_data4, train_labels4, dev_data4, dev_labels4)[1]))\n",
    "\n",
    "print('Features: pixel features, filetype dummies\\nBest Accuracy: {}, c={}\\n'.format(\n",
    "    LR_accuracy_c(train_data5, train_labels5, dev_data5, dev_labels5)[0],\n",
    "    LR_accuracy_c(train_data5, train_labels5, dev_data5, dev_labels5)[1]))\n",
    "\n",
    "print('Features: size, height, width, h_to_w, filetype\\nBest Accuracy: {}, c={}\\n'.format(\n",
    "    LR_accuracy_c(train_data6, train_labels6, dev_data6, dev_labels6)[0],\n",
    "    LR_accuracy_c(train_data6, train_labels6, dev_data6, dev_labels6)[1]))\n",
    "\n",
    "print('Features: size, h_to_w, filetype\\nBest Accuracy: {}, c={}\\n'.format(\n",
    "    LR_accuracy_c(train_data7, train_labels7, dev_data7, dev_labels7)[0],\n",
    "    LR_accuracy_c(train_data7, train_labels7, dev_data7, dev_labels7)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.803, 0.841, 0.858, 0.853, 0.849, 0.849, 0.848, 0.848, 0.85, 0.85],\n",
       " [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0, 5.0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg(train_data2, train_labels2, dev_data2, dev_labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Layer Neural Network**  \n",
    "**Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build layers of neural net\n",
    "\n",
    "def build_model(hp):\n",
    "    # Begins the linear arrangment of layers\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "    # Creates a fully-connected layer. A layer is fully connected to the layer that preceds it.\n",
    "    # Dense1_units number of nodes in the layer, choses a value between 1 and 100 based on optimization \n",
    "      tf.keras.layers.Dense(units=hp.Choice('dense1_units', values=[1, 100]), activation='relu'),\n",
    "\n",
    "    # Uses dropout regularization by dropping 20% before next layer\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    # 2 nodes in final output for logo/not logo\n",
    "      tf.keras.layers.Dense(2, activation='softmax') \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Other activation functions: activation='sigmoid'\n",
    "# Other optimizers to try - Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\user\\\\Documents\\\\Berkeley_MIDS\\\\W207_Machine_Learning\\\\w207_final_project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project C:\\Users\\user\\Documents\\Berkeley_MIDS\\W207_Machine_Learning\\w207_final_project\\keras_tuner\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "# Use keras random search with build_model function to maximize accuracy \n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='C:\\\\Users\\\\user\\\\Documents\\\\Berkeley_MIDS\\\\W207_Machine_Learning\\\\w207_final_project',\n",
    "    project_name='keras_tuner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55/71 [======================>.......] - ETA: 0s - loss: 3.3347 - accuracy: 0.59 - ETA: 0s - loss: 3.4129 - accuracy: 0.5920"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a NewWriteableFile: C:\\Users\\user\\Documents\\Berkeley_MIDS\\W207_Machine_Learning\\w207_final_project\\keras_tuner\\trial_99834874d955a686d083597d5168c5ee\\checkpoints\\epoch_0\\checkpoint_temp_df2054dae9294905a733c5789e930905/part-00000-of-00001.data-00000-of-00001.tempstate15128673017566932951 : The system cannot find the path specified.\r\n; No such process [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-b2378e69b58e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m tuner.search(train_data2, train_labels2,\n\u001b[0;32m      3\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m              validation_data=(dev_data2, dev_labels2))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1297\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m                 self.model.save_weights(\n\u001b[1;32m-> 1299\u001b[1;33m                     filepath, overwrite=True, options=self._options)\n\u001b[0m\u001b[0;32m   1300\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m   2099\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[0;32m   2100\u001b[0m             % (optimizer,))\n\u001b[1;32m-> 2101\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m       \u001b[1;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1200\u001b[1;33m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[0;32m   1201\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1144\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    267\u001b[0m           \u001b[1;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m           \u001b[1;31m# device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m           \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[0;32m   1729\u001b[0m       return save_v2_eager_fallback(\n\u001b[0;32m   1730\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1731\u001b[1;33m           ctx=_ctx)\n\u001b[0m\u001b[0;32m   1732\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[0;32m   1749\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1751\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   1752\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: C:\\Users\\user\\Documents\\Berkeley_MIDS\\W207_Machine_Learning\\w207_final_project\\keras_tuner\\trial_99834874d955a686d083597d5168c5ee\\checkpoints\\epoch_0\\checkpoint_temp_df2054dae9294905a733c5789e930905/part-00000-of-00001.data-00000-of-00001.tempstate15128673017566932951 : The system cannot find the path specified.\r\n; No such process [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "# Start search with training data\n",
    "tuner.search(train_data2, train_labels2,\n",
    "             epochs=10,\n",
    "             validation_data=(dev_data2, dev_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Get results\n",
    "tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this specifies what kind of layers are going to be present in the neural net\n",
    "#Begins the linear arrangment of layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "  #tf.keras.layers.Flatten(input_shape=(150528, 1)),\n",
    "    \n",
    "#Creates a fully-connected layer. A layer is fully connected to the layer that preceds it.\n",
    "#128 nodes in the layer\n",
    "  tf.keras.layers.Dense(50, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(2, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 0s 871us/step - loss: 0.4707 - accuracy: 0.7882\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 786us/step - loss: 0.4720 - accuracy: 0.7855\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 815us/step - loss: 0.4696 - accuracy: 0.7829\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 773us/step - loss: 0.4724 - accuracy: 0.7886\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 0s 801us/step - loss: 0.4714 - accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 942us/step - loss: 0.4743 - accuracy: 0.7740\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 829us/step - loss: 0.4664 - accuracy: 0.7909\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 815us/step - loss: 0.4702 - accuracy: 0.7815\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 0s 829us/step - loss: 0.4659 - accuracy: 0.7842\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 759us/step - loss: 0.4692 - accuracy: 0.7749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2024fb386c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Epoch = number of times the model sees all of the training\n",
    "model.fit(train_data2, train_labels2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2252, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 602\n",
      "Trainable params: 602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 582us/step - loss: 0.5121 - accuracy: 0.7483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5120877623558044, 0.7483355402946472]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_data2, dev_labels2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
